{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d7ec2e",
   "metadata": {
    "id": "67d7ec2e"
   },
   "source": [
    "# **Default of Credit Card Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nqhy1SE7_G2D",
   "metadata": {
    "id": "nqhy1SE7_G2D"
   },
   "source": [
    "# **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ff4d8",
   "metadata": {
    "id": "385ff4d8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix #Cross checking the values\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qUB3s8Hl8l97",
   "metadata": {
    "id": "qUB3s8Hl8l97"
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"default of credit card clients.xls\", header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G6jlQRzwtP02",
   "metadata": {
    "id": "G6jlQRzwtP02"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da58fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "96da58fb",
    "outputId": "ae16ad29-185f-4d27-b1c4-6ef8b54e1f32"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa62ea",
   "metadata": {
    "id": "2afa62ea"
   },
   "source": [
    "**We split the dataset to distinguish between clients who consistently paid their dues on time over six months and those who defaulted on payments in at least one of the months, aiding in analyzing credit behavior and assessing default risk.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11aec3",
   "metadata": {
    "id": "9b11aec3"
   },
   "outputs": [],
   "source": [
    "df1 = df[(df['PAY_0'] == -1) & (df['PAY_2'] == -1) & (df['PAY_3'] == -1) & (df['PAY_4'] == -1) & (df['PAY_5'] == -1) & (df['PAY_6'] == -1)]\n",
    "df2 = df[(df['PAY_0'] !=-1) & (df['PAY_2'] != -1) & (df['PAY_3'] != -1) & (df['PAY_4'] != -1) & (df['PAY_5'] != -1) & (df['PAY_6'] != -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5ad97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9dd5ad97",
    "outputId": "447c2a72-27f9-4562-87df-3a3d7b569991"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0512b",
   "metadata": {
    "id": "6df0512b"
   },
   "source": [
    "# Variable information\n",
    "> LIMIT_BAL : Amount of the given credit ($) (individual and his/her family)\n",
    "\n",
    "> SEX : Gender (1 = male; 2 = female)\n",
    "\n",
    "> EDUCATION : 1 = graduate school; 2 = university; 3 = high school; 4 = others\n",
    "\n",
    "> MARRAIGE : 1 = Maried 2 = Single 3 = others\n",
    "\n",
    "> AGE : in years\n",
    "\n",
    "> PAY_0,PAY_2 to PAY_6 : History of past payment (September 2005, August 2005, July 2005, June 2005, May 2005, April 2005)\n",
    "                         -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .\n",
    "                         8 = payment delay for eight months; 9 = payment delay for nine months and above\n",
    "\n",
    "> BILL_AMT1 to BILL_AMT6 : Amount of bill ($) (Sep 2005 to April 2005)\n",
    "\n",
    "> PAY_AMT1 to PAY_AMT6 : Amount of previous payment ($) (Sep 2005 to April 2005)\n",
    "\n",
    "> default payment next month : response variable (Yes = 1, No = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c8bfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "750c8bfe",
    "outputId": "61e14e8c-99a7-434d-a581-3f1501f4dae2"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab4cbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73ab4cbc",
    "outputId": "18110db9-9a07-4882-ec59-39cf08b3b105"
   },
   "outputs": [],
   "source": [
    "# converting data type to int\n",
    "df = df.astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6iWKSCZZsjA2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "6iWKSCZZsjA2",
    "outputId": "c6854ff1-32ba-426b-cdfa-e8ac0f67bd11"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9aec87",
   "metadata": {
    "id": "4d9aec87"
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a1dd60",
   "metadata": {
    "id": "f1a1dd60"
   },
   "source": [
    "**Default Payment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc47d33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "0bc47d33",
    "outputId": "06129574-390d-425f-d7a1-31f51ec9733a"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "sns.countplot(x='default payment next month', data=df, ax=axes[0])\n",
    "axes[0].set_title('All Data')\n",
    "axes[0].set_xlabel('Default Payment')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels(['No', 'Yes'])\n",
    "sns.countplot(x='default payment next month', data=df1, ax=axes[1])\n",
    "axes[1].set_title('Timely Payments')\n",
    "axes[1].set_xlabel('Default Payment')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].set_xticklabels(['No', 'Yes'])\n",
    "sns.countplot(x='default payment next month', data=df2, ax=axes[2])\n",
    "axes[2].set_title('Delayed Payments')\n",
    "axes[2].set_xlabel('Default Payment')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_xticks([0, 1])\n",
    "axes[2].set_xticklabels(['No', 'Yes'])\n",
    "plt.suptitle('Counts of Default Payment Next Month')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94be91",
   "metadata": {
    "id": "4b94be91"
   },
   "source": [
    "This highlights a lower default rate among clients who made timely payments compared to those with delayed payments, emphasizing the significance of payment punctuality in credit risk management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aedc00",
   "metadata": {
    "id": "07aedc00"
   },
   "source": [
    "**Age Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fkr46KdBb4T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "7fkr46KdBb4T",
    "outputId": "1e0a3b3f-b3fe-4895-c4cc-3f95f07f8a7d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "sns.lineplot(data=df['AGE'].value_counts(), label='All Data')\n",
    "sns.lineplot(data=df1['AGE'].value_counts(), label='Timely Payments')\n",
    "sns.lineplot(data=df2['AGE'].value_counts(), label='Delayed Payments')\n",
    "sns.lineplot(data=df[df['default payment next month'] == 1]['AGE'].value_counts(), label='Defaulted')\n",
    "plt.title('Age Count Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf1612d",
   "metadata": {
    "id": "bbf1612d"
   },
   "source": [
    "This graph reveals that we mostly have data for age group beween their late 20s and mid 40s.\n",
    "It can also be observed that most defaulters and clients who have consistently delayed in payements are in the age of 20-30."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b712fe90",
   "metadata": {
    "id": "b712fe90"
   },
   "source": [
    "**Gender Count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c7abd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "760c7abd",
    "outputId": "410a4cc4-058a-491e-9455-c2967f493afc"
   },
   "outputs": [],
   "source": [
    "df[['SEX','EDUCATION','MARRIAGE']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff1c05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "35ff1c05",
    "outputId": "0f391289-9eb7-41e1-b4eb-e6c7ec81fccd"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "sns.countplot(x='SEX', data=df, ax=axes[0])\n",
    "axes[0].set_title('All Data')\n",
    "axes[0].set_xlabel('Gender')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels(['Male', 'Female'])\n",
    "\n",
    "sns.countplot(x='SEX', data=df1, ax=axes[1])\n",
    "axes[1].set_title('Timely Payments')\n",
    "axes[1].set_xlabel('Gender')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].set_xticklabels(['Male', 'Female'])\n",
    "\n",
    "sns.countplot(x='SEX', data=df2, ax=axes[2])\n",
    "axes[2].set_title('Delayed Payments')\n",
    "axes[2].set_xlabel('Gender')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_xticks([0, 1])\n",
    "axes[2].set_xticklabels(['Male', 'Female'])\n",
    "plt.suptitle('Gender Distribution Comparison')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf5507",
   "metadata": {
    "id": "aeaf5507"
   },
   "source": [
    "This analysis reveals that the dataset comprises more females than males. It can also be observed that althought females have equal distribution between doing timely payments or not, more percentage of males are likely to have delayed payment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a9087",
   "metadata": {
    "id": "c18a9087"
   },
   "source": [
    "**Education Level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769e604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8769e604",
    "outputId": "121abddc-fda3-4423-af06-19e61d8ea49b"
   },
   "outputs": [],
   "source": [
    "print(df['EDUCATION'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0c2c92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc0c2c92",
    "outputId": "959556f6-c681-4aa2-bb23-f0743bad1a29"
   },
   "outputs": [],
   "source": [
    "# 0,5,6 shouldn't be there for education\n",
    "df.loc[(df.EDUCATION == 5) | (df.EDUCATION == 6) | (df.EDUCATION == 0),'EDUCATION'] = 4\n",
    "print(df['EDUCATION'].value_counts())\n",
    "df1.loc[(df1.EDUCATION == 5) | (df1.EDUCATION == 6) | (df1.EDUCATION == 0),'EDUCATION'] = 4\n",
    "print(df1['EDUCATION'].value_counts())\n",
    "df2.loc[(df2.EDUCATION == 5) | (df2.EDUCATION == 6) | (df2.EDUCATION == 0),'EDUCATION'] = 4\n",
    "print(df2['EDUCATION'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b3acea",
   "metadata": {
    "id": "31b3acea"
   },
   "source": [
    "The education feature in our dataset contains numerical values such as 0, 5, and 6, which do not correspond to valid educational categories. To rectify this inconsistency, these values were replaced with 4, representing a more appropriate category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f032a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "a26f032a",
    "outputId": "4c5e67a2-aa02-4d9e-f63f-9ecd23a64e82"
   },
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df.assign(Dataset='All Data'), df1.assign(Dataset='Timely Payments'), df2.assign(Dataset='Delayed Payments')])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='EDUCATION', hue='Dataset', data=combined_df)\n",
    "plt.title('Education Background')\n",
    "plt.xlabel('Education Level')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=[0, 1, 2, 3], labels=['Grad School', 'University', 'High School', 'Others'])\n",
    "plt.legend(title='Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b15de0",
   "metadata": {
    "id": "a9b15de0"
   },
   "source": [
    "It indicates that individuals with university education form the largest proportion across all datasets, while those with graduate school education are the next most common. However individuals categorized as \"Others\" (level 4) have the highest percentage of delayed payments compared to other education levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ed2c4",
   "metadata": {
    "id": "fe3ed2c4"
   },
   "source": [
    "**Maratial Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce509cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ce509cc",
    "outputId": "2a3a07c0-ac8a-493e-c5cb-71aabd808aca"
   },
   "outputs": [],
   "source": [
    "print(df['MARRIAGE'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de359fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7de359fd",
    "outputId": "4db24385-cce6-4e12-9985-6abe1995b18f"
   },
   "outputs": [],
   "source": [
    "# 0 shouldn't be there for marraige\n",
    "df.loc[(df.MARRIAGE == 0),'MARRIAGE'] = 3\n",
    "print(df['MARRIAGE'].value_counts())\n",
    "df1.loc[(df1.MARRIAGE == 0),'MARRIAGE'] = 3\n",
    "print(df1['MARRIAGE'].value_counts())\n",
    "df2.loc[(df2.MARRIAGE == 0),'MARRIAGE'] = 3\n",
    "print(df2['MARRIAGE'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642ac2fa",
   "metadata": {
    "id": "642ac2fa"
   },
   "source": [
    "**Marriage category '0' is not valid and hence replaced with category '3' that is others in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc549c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "7cc549c7",
    "outputId": "937a226d-d80b-43de-9689-82ff826a3b6e"
   },
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df.assign(Dataset='All Data'), df1.assign(Dataset='Timely Payments'), df2.assign(Dataset='Delayed Payments')])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='MARRIAGE', hue='Dataset', data=combined_df)\n",
    "plt.title('Marital Status')\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=[0,1,2], labels=['Married','Single','Others'])\n",
    "plt.legend(title='Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581392b",
   "metadata": {
    "id": "b581392b"
   },
   "source": [
    "Marriage category 1 (Married) appears to have higher proportion of delayed payments compared to timely payments, with approximately 65.42% of clients paying late. This suggests that individuals who are married may be more prone to delaying their credit card payments.\n",
    "Further analysis could explore potential reasons behind this trend, such as financial responsibilities shared within a household or differing spending habits between married and unmarried individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc27ec08",
   "metadata": {
    "id": "dc27ec08"
   },
   "source": [
    "**Delays in payment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c43b3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "b8c43b3f",
    "outputId": "54019296-67b6-4b43-c9c4-613692e9d6be"
   },
   "outputs": [],
   "source": [
    "df[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9324869d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "9324869d",
    "outputId": "76eaf1a3-b03e-4071-9a8c-40f9415a2523"
   },
   "outputs": [],
   "source": [
    "df[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']].apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc564d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "bcc564d8",
    "outputId": "5b923ad4-b6d0-4c30-e5a5-6f9ddb7d2ede"
   },
   "outputs": [],
   "source": [
    "df[(df['PAY_0'] == -2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eabde5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "f3eabde5",
    "outputId": "85b2c92f-f78f-4434-aa19-3b2443b3f07d"
   },
   "outputs": [],
   "source": [
    "df[(df['PAY_0'] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc472aef",
   "metadata": {
    "id": "cc472aef"
   },
   "source": [
    "It was observed that -2 indicates that the balance was paid in full, and there were no transactions during this period, implying that the credit card account was inactive.\n",
    "0 signifies that the customer paid the minimum due amount but did not settle the entire balance. This means the customer paid enough to maintain their account in good standing but did carry forward a balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cf3df7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "72cf3df7",
    "outputId": "92c2fdb9-bd93-450d-e082-23755178cdab"
   },
   "outputs": [],
   "source": [
    "delay = ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "delay_month = ['September 2005', 'August 2005', 'July 2005', 'June 2005', 'May 2005', 'April 2005']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(delay, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.countplot(x=col, data=df)\n",
    "    plt.title(f'Count of {col} ({delay_month[i-1]})')\n",
    "    plt.xlabel(f'{col}')\n",
    "    plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f83a5",
   "metadata": {
    "id": "3a1f83a5"
   },
   "source": [
    "**Bill amount over months (Sept 2005 to April 2005)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fecc2dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "9fecc2dd",
    "outputId": "27db7bfd-4936-4053-8b22-cee04304b863"
   },
   "outputs": [],
   "source": [
    "df[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98f5ce",
   "metadata": {
    "id": "5f98f5ce"
   },
   "source": [
    "Let us assume -ve is credit in account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f4080",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "e86f4080",
    "outputId": "30a6c3b8-f016-464b-fafd-4d8fb73c6b96"
   },
   "outputs": [],
   "source": [
    "bill_col = ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\n",
    "bill_month = ['Sep 2005', 'Aug 2005', 'Jul 2005', 'Jun 2005', 'May 2005', 'April 2005']\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(bill_col, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(df[col], bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {col} ({bill_month[i-1]})')\n",
    "    plt.xlabel(f'{col}')\n",
    "    plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3db07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "91f3db07",
    "outputId": "f0f984bd-b5f0-498b-88e4-fd59015a15b1"
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Bill Month': bill_month,\n",
    "    'Bill Amount (mean)': [df[col].mean() for col in bill_col],\n",
    "    'Bill Amount (median)': [df[col].median() for col in bill_col],\n",
    "    'Bill Amount (std)': [df[col].std() for col in bill_col]\n",
    "}\n",
    "payment_summary_df = pd.DataFrame(data)\n",
    "payment_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d06c2",
   "metadata": {
    "id": "474d06c2"
   },
   "source": [
    "\n",
    "\n",
    "**Paid amount over months (Sept 2005 to April 2005)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326fce22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "326fce22",
    "outputId": "b23599d9-469c-48b9-b516-26923f0b146d"
   },
   "outputs": [],
   "source": [
    "df[['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b523b67e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "b523b67e",
    "outputId": "347420bf-bfd0-4be7-9033-95183261a110"
   },
   "outputs": [],
   "source": [
    "paid_col = ['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "payment_month = ['September 2005', 'August 2005', 'July 2005', 'June 2005', 'May 2005', 'April 2005']\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(paid_col, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(df[col], bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {col} ({payment_month[i-1]})')\n",
    "    plt.xlabel('Payment Amount')\n",
    "    plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488dc914",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "488dc914",
    "outputId": "0a04822d-4581-4408-f4e9-9fca45220241"
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Payment Month': payment_month,\n",
    "    'Payment Amount (mean)': [df[col].mean() for col in paid_col],\n",
    "    'Payment Amount (median)': [df[col].median() for col in paid_col],\n",
    "    'Payment Amount (std)': [df[col].std() for col in paid_col]\n",
    "}\n",
    "payment_summary_df = pd.DataFrame(data)\n",
    "payment_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DOrjdcolUW9A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "DOrjdcolUW9A",
    "outputId": "8b53efff-eb32-4b06-f1f5-dcb12b2952d6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(df['LIMIT_BAL'], bins=30, color='skyblue', edgecolor='black')\n",
    "\n",
    "plt.title('Distribution of Credit Limit')\n",
    "\n",
    "plt.xlabel('Credit Limit')\n",
    "\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ab6ef",
   "metadata": {
    "id": "276ab6ef"
   },
   "source": [
    "## Corelations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ecea8f",
   "metadata": {
    "id": "d8ecea8f"
   },
   "source": [
    "**Gender & Default Payment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b98ac40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b98ac40",
    "outputId": "ad5a69a5-c5ad-4303-ab2e-4a6596e4020e"
   },
   "outputs": [],
   "source": [
    "df_gender_y = df.groupby(['SEX','default payment next month']).size()\n",
    "# default payment next month : response variable (Yes = 1, No = 0)\n",
    "# SEX : Gender (1 = male; 2 = female)\n",
    "print(df_gender_y)\n",
    "p_sex = df_gender_y.groupby(['SEX'],group_keys=False).apply(lambda x: 100 * x / float(x.sum()))\n",
    "print(p_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce4b31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "14ce4b31",
    "outputId": "88abe9d4-d94d-43dc-a77d-8e626030b66b"
   },
   "outputs": [],
   "source": [
    "labels = ['Male - No', 'Male - Yes', 'Female - No', 'Female - Yes']\n",
    "plt.pie(p_sex.values, labels=labels, autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Default Payment by Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145d852f",
   "metadata": {
    "id": "145d852f"
   },
   "source": [
    "The analysis reveals that females have a slightly lower default rate compared to males, indicating potential gender-based differences in credit risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63377938",
   "metadata": {
    "id": "63377938"
   },
   "source": [
    "**Education vs Default Payment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af8c29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22af8c29",
    "outputId": "f0cdd568-afd8-4a74-f4aa-024da505335a"
   },
   "outputs": [],
   "source": [
    "df_education_y = df.groupby(['EDUCATION', 'default payment next month']).size()\n",
    "print(df_education_y)\n",
    "# EDUCATION : 1 = graduate school; 2 = university; 3 = high school; 4 = others\n",
    "p_education = df_education_y.groupby('EDUCATION',group_keys=False).apply(lambda x: 100 * x / float(x.sum()))\n",
    "print(p_education)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f3ccd",
   "metadata": {
    "id": "fc7f3ccd"
   },
   "source": [
    "Its observed that distribution is slightly correlated on gender. Males are more likely to default next month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84a3fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "7f84a3fa",
    "outputId": "8360753c-97b5-445a-938f-90b22f872684"
   },
   "outputs": [],
   "source": [
    "labels = ['Graduate School - No', 'Graduate School - Yes','University - No', 'University - Yes',\n",
    "                    'High School - No', 'High School - Yes','Others - No', 'Others - Yes']\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.pie(p_education.values, labels=labels, autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Default Payment by Education Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X-jFlrx2e--x",
   "metadata": {
    "id": "X-jFlrx2e--x"
   },
   "source": [
    "The data suggests that individuals with higher education levels tend to have lower default rates, with the default rate decreasing as education level increases. This highlights the potential correlation between education level and credit worthiness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2WLYe6gCT9-F",
   "metadata": {
    "id": "2WLYe6gCT9-F"
   },
   "source": [
    "**Outlier Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "THuo3Sf8T8Sk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "THuo3Sf8T8Sk",
    "outputId": "741b0300-e190-4958-fc49-44c33ff48ee2"
   },
   "outputs": [],
   "source": [
    "def outliers_plot(df, columns):\n",
    "    fig, axes = plt.subplots(nrows=len(columns), ncols=1, figsize=(10, len(columns)*5))\n",
    "\n",
    "    for i, column in enumerate(columns):\n",
    "        ax = axes[i] if len(columns) > 1 else axes\n",
    "        ax.boxplot(df[column], vert=False)\n",
    "        ax.set_title(f'Outlier Analysis for {column}')\n",
    "        ax.set_xlabel(column)\n",
    "        ax.set_ylabel('Outlier Detection')\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "columns_to_analyze = ['LIMIT_BAL', 'AGE', 'BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6','PAY_AMT1','PAY_AMT2' ,'PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']\n",
    "outliers_plot(df, columns_to_analyze)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502793ec",
   "metadata": {
    "id": "502793ec"
   },
   "source": [
    "**Correlation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c291c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e34c291c",
    "outputId": "b8126e71-9b33-48db-9e9f-3125ca9a89a1"
   },
   "outputs": [],
   "source": [
    "corr = df[df.columns].corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask=np.triu(np.ones_like(corr, dtype=bool)) # to hide the lower triangle (including diagonal) of the correlation matrix.\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(corr, mask=mask, annot=True, annot_kws={'size': 10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HUUPdHyiiKFu",
   "metadata": {
    "id": "HUUPdHyiiKFu"
   },
   "source": [
    "The above code generates a lower triangular correlation matrix\n",
    "Each cell denotes the correlation coefficient between two variables, where one variable corresponds to the row index and the other variable corresponds to the column index. The diagonal of the correlation matrix always consists of correlation coefficients of 1.0, indicating perfect correlation, as each variable is perfectly correlated with itself. Correlation is a statistical tool used to quantify the strength and direction of the relationship between two variables. It measures how much the variables change together. The correlation coefficient, denoted by\n",
    "\n",
    "r, it varies between -1 and 1.\n",
    "\n",
    "\n",
    "\n",
    " r=1 : Represents a perfect positive correlation, where both variables increase together.\n",
    "r\n",
    "=\n",
    "âˆ’\n",
    "1\n",
    ": Signifies a perfect negative correlation, where one variable increases as the other decreases.\n",
    "r\n",
    "=\n",
    "0\n",
    ": Indicates no correlation, suggesting no linear relationship between the variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hevMUo6TN5ln",
   "metadata": {
    "id": "hevMUo6TN5ln"
   },
   "source": [
    "Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2rlyUQ6niqk4",
   "metadata": {
    "id": "2rlyUQ6niqk4"
   },
   "outputs": [],
   "source": [
    "df_stnd = df.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vyWX0_R-iIu7",
   "metadata": {
    "id": "vyWX0_R-iIu7"
   },
   "outputs": [],
   "source": [
    "categorical_data=df_stnd[['SEX','EDUCATION','MARRIAGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6','default payment next month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TO726SXp1uyN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TO726SXp1uyN",
    "outputId": "52221b3b-a327-4080-b8fb-7d3a0fa06348"
   },
   "outputs": [],
   "source": [
    "continuous_data = df_stnd[['LIMIT_BAL', 'AGE', 'BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6','PAY_AMT1','PAY_AMT2' ,'PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']]\n",
    "print(continuous_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_c-aibA7Anyy",
   "metadata": {
    "id": "_c-aibA7Anyy"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(continuous_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2Gf0-nF-Tfpp",
   "metadata": {
    "id": "2Gf0-nF-Tfpp"
   },
   "outputs": [],
   "source": [
    "X_standardized_df= pd.DataFrame(X_standardized, columns=continuous_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KBeo0yCaUghk",
   "metadata": {
    "id": "KBeo0yCaUghk"
   },
   "outputs": [],
   "source": [
    "X_standardized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cNpbu-hb8n",
   "metadata": {
    "id": "78cNpbu-hb8n"
   },
   "outputs": [],
   "source": [
    "df_final = pd.concat([X_standardized_df, categorical_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wSy96i7Dl48z",
   "metadata": {
    "id": "wSy96i7Dl48z"
   },
   "outputs": [],
   "source": [
    "for col in categorical_data.columns:\n",
    "    X_standardized_df[col] = categorical_data[col].values\n",
    "df_final = X_standardized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C3sQb9a-kUpk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "C3sQb9a-kUpk",
    "outputId": "f3e13087-9b1f-4cc7-b7b1-325dbd6bea35"
   },
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MKUZzaHv1SDD",
   "metadata": {
    "id": "MKUZzaHv1SDD"
   },
   "source": [
    "**Balancing the dataset**\n",
    "Using Oversample (smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zpwe2U9q2gww",
   "metadata": {
    "id": "zpwe2U9q2gww"
   },
   "outputs": [],
   "source": [
    "class_count_0, class_count_1 = df_final['default payment next month'].value_counts()\n",
    "\n",
    "class_0 = df_final [df_final['default payment next month'] == 0]\n",
    "class_1 =df_final[df_final['default payment next month'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QYC3uOWB23Wf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYC3uOWB23Wf",
    "outputId": "f007573b-02b6-4c3d-dcc1-a82c626e759a"
   },
   "outputs": [],
   "source": [
    "print('class 0:', class_0.shape)\n",
    "print('\\nclass 1:', class_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7Kz3w8FM51ge",
   "metadata": {
    "id": "7Kz3w8FM51ge"
   },
   "outputs": [],
   "source": [
    "#class_1_over = class_1.sample(class_count_0, replace=True)\n",
    "\n",
    "#test_under = pd.concat([class_1_over, class_0], axis=0)\n",
    "\n",
    "# print the number of class count\n",
    "#print('class count of 1 and 0:\\n', test_under['default payment next month'].value_counts())\n",
    "\n",
    "#test_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a_Av1e4XnfsF",
   "metadata": {
    "id": "a_Av1e4XnfsF"
   },
   "outputs": [],
   "source": [
    "x = df_final.iloc[:, :-1]\n",
    "y = df_final.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U07q3KKfFw17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U07q3KKfFw17",
    "outputId": "e1ce092f-da02-40aa-827b-fe5ffb51ed0a"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S5rm7zNuFtKU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "S5rm7zNuFtKU",
    "outputId": "6eea94f6-5e57-442a-e5dc-383c0cadca7c"
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UEnYmujL2_uZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEnYmujL2_uZ",
    "outputId": "2c6c6525-7f5d-4c05-a711-61f8a8cf94e3"
   },
   "outputs": [],
   "source": [
    "# Assuming x and y are your features and target variable respectively\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, stratify=y, test_size=0.3)\n",
    "\n",
    "# Dynamically adjust k_neighbors based on the class distribution\n",
    "smote = SMOTE(k_neighbors=20)\n",
    "\n",
    "# fit target and predictor variable\n",
    "x_smote , y_smote = smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "print('Original dataset shape:', Counter(Y_train))\n",
    "print('Resampled dataset shape:', Counter(y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2hyG7qVSFX2G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hyG7qVSFX2G",
    "outputId": "a1693e05-2333-4224-d95f-653a2d30fa58"
   },
   "outputs": [],
   "source": [
    "x_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JRVTNWr0F79v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRVTNWr0F79v",
    "outputId": "3683e080-7f2b-4622-abeb-39d472d9556b"
   },
   "outputs": [],
   "source": [
    "y_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EIcmsZyEoUaW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "EIcmsZyEoUaW",
    "outputId": "05ffff43-244f-4a51-b4a2-67a2205bac3c"
   },
   "outputs": [],
   "source": [
    "x_smote.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xX1BYKoPGRDe",
   "metadata": {
    "id": "xX1BYKoPGRDe"
   },
   "source": [
    "**Implementation of PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nbdZ8GUzpn0s",
   "metadata": {
    "id": "nbdZ8GUzpn0s"
   },
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, explained_variance_threshold=0.95):\n",
    "        self.explained_variance_threshold = explained_variance_threshold\n",
    "        self.n_components = None\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Mean of each feature\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        \n",
    "        X -= self.mean\n",
    "        #Centering the data is crucial for PCA because it ensures that the principal components \n",
    "        #represent directions of maximum variance\n",
    "        \n",
    "        # Covariance matrix\n",
    "        cov_matrix = np.cov(X.T)\n",
    "        \n",
    "        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "        # Sort eigenvectors based on eigenvalues, this prioritizes the principal components with the most variance.\n",
    "        eigenvectors = eigenvectors.T\n",
    "        idxs = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvectors = eigenvectors[idxs]\n",
    "        \n",
    "        explained_variance_ratio = np.cumsum(eigenvalues[idxs]) / np.sum(eigenvalues)\n",
    "        \n",
    "        # Determine number of components to retain explained variance\n",
    "        self.n_components = np.argmax(explained_variance_ratio >= self.explained_variance_threshold) + 1\n",
    "        # Store the first n_components eigenvectors as principal components\n",
    "        self.components = eigenvectors[:self.n_components]\n",
    "        \n",
    "    # Project data onto the principal components\n",
    "    def transform(self, X):\n",
    "        X -= self.mean\n",
    "        return np.dot(X, self.components.T)\n",
    "    \n",
    "    # Transform data back to the original space\n",
    "    def inverse_transform(self, X_transformed):\n",
    "        return np.dot(X_transformed, self.components) + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GOQd9tRkcTIT",
   "metadata": {
    "id": "GOQd9tRkcTIT"
   },
   "outputs": [],
   "source": [
    "# Apply PCA to the oversampled data with 95% explained variance threshold\n",
    "pca = PCA(explained_variance_threshold=0.95)\n",
    "pca.fit(x_smote)\n",
    "\n",
    "# Transform the oversampled data onto the new lower-dimensional space\n",
    "X_train_transformed = pca.transform(x_smote)\n",
    "X_test_transformed = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YKJrsSciCRrX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YKJrsSciCRrX",
    "outputId": "0d424732-d476-4136-c6b7-ab9af21bcc86"
   },
   "outputs": [],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "niD1SzX_GfFv",
   "metadata": {
    "id": "niD1SzX_GfFv"
   },
   "source": [
    "# MODEL IMPLEMENTATION ON OVERSAMPLED DATA\n",
    "\n",
    "\n",
    "*   Logistic Regression (Implementation of Logistic Regression with regularization and hyperparameter tuning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uuvvj2VHaiJX",
   "metadata": {
    "id": "uuvvj2VHaiJX"
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionWithRegularization:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=3000, lambda_param=0.01, regularization=None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.lambda_param = lambda_param\n",
    "        self.regularization = regularization\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):                      #sigmoid\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def _compute_regularization_term(self):\n",
    "        if self.regularization == 'ridge':\n",
    "            return self.lambda_param * np.sum(self.weights**2)\n",
    "        elif self.regularization == 'lasso':\n",
    "            return self.lambda_param * np.sum(np.abs(self.weights))\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "      linear_model = np.dot(X, self.weights) + self.bias\n",
    "      return self.sigmoid(linear_model)\n",
    "\n",
    "    def compute_loss(self, y, predictions):   # Loss calculation with regularization term\n",
    "\n",
    "      reg_term = 0\n",
    "      if self.regularization == 'ridge':\n",
    "          reg_term = self.lambda_param * np.sum(self.weights**2)\n",
    "      elif self.regularization == 'lasso':\n",
    "          reg_term = self.lambda_param * np.sum(np.abs(self.weights))\n",
    "      return -np.mean(y * np.log(predictions + 1e-15) + (1 - y) * np.log(1 - predictions + 1e-15)) + reg_term\n",
    "\n",
    "\n",
    "    def fit(self, X, y, return_history=True):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.weights = np.zeros(num_features)\n",
    "        self.bias = 0\n",
    "        loss_history = []  # List to store the loss values\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_predicted = self.sigmoid(linear_model)\n",
    "\n",
    "\n",
    "            loss = -np.mean(y * np.log(y_predicted + 1e-15) + (1 - y) * np.log(1 - y_predicted + 1e-15)) # Compute the regular loss\n",
    "\n",
    "            loss += self._compute_regularization_term() # Add regularization term\n",
    "            if return_history:\n",
    "                loss_history.append(loss)\n",
    "\n",
    "            # Compute gradients\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / num_samples) * np.sum(y_predicted - y)\n",
    "\n",
    "            # Apply regularization\n",
    "            if self.regularization == 'ridge':\n",
    "                dw += 2 * self.lambda_param * self.weights\n",
    "            elif self.regularization == 'lasso':\n",
    "                dw += self.lambda_param * np.sign(self.weights)\n",
    "\n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "        if return_history:\n",
    "            return loss_history\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.sigmoid(linear_model)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return y_predicted_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "omUhIwfDbmtL",
   "metadata": {
    "id": "omUhIwfDbmtL"
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "lambda_params = [0.1, 0.01, 0.001]\n",
    "regularizations = ['ridge', 'lasso', None]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "train_losses = []\n",
    "cv_losses = []\n",
    "validation_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MPdnIiOkb2jK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPdnIiOkb2jK",
    "outputId": "5fbab93f-4b23-4bc9-ccb5-50d5ef5b8c70"
   },
   "outputs": [],
   "source": [
    "for lr in learning_rates:\n",
    "    for lambda_param in lambda_params:\n",
    "        for regularization in regularizations:\n",
    "            model = LogisticRegressionWithRegularization(learning_rate=lr, lambda_param=lambda_param, regularization=regularization)\n",
    "            model.fit(X_train_transformed, y_smote)\n",
    "            y_pred = model.predict(X_test_transformed)\n",
    "            train_pred = model.predict_proba(X_train_transformed)\n",
    "            val_pred = model.predict_proba(X_test_transformed)\n",
    "            train_loss = model.compute_loss(y_smote, train_pred)\n",
    "            validation_loss = model.compute_loss(Y_test, val_pred)\n",
    "            train_losses.append(train_loss)\n",
    "            validation_losses.append(validation_loss)\n",
    "            accuracy = np.mean(y_pred == Y_test)\n",
    "            print(f\"Accuracy with lr={lr}, lambda={lambda_param}, regularization={regularization}  : {round(accuracy,3)}\")\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {'learning_rate': lr, 'lambda_param': lambda_param, 'regularization': regularization}\n",
    "\n",
    "\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_uHyYqNTBQku",
   "metadata": {
    "id": "_uHyYqNTBQku"
   },
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(y_true, y_pred):          #confusion matrix\n",
    "\n",
    "    TP = TN = FP = FN = 0\n",
    "\n",
    "    for actual, predicted in zip(y_true, y_pred):\n",
    "        if actual == 1 and predicted == 1:\n",
    "            TP += 1\n",
    "        elif actual == 0 and predicted == 0:\n",
    "            TN += 1\n",
    "        elif actual == 0 and predicted == 1:\n",
    "            FP += 1\n",
    "        elif actual == 1 and predicted == 0:\n",
    "            FN += 1\n",
    "\n",
    "    confusion_matrix = [\n",
    "        [TN, FP],\n",
    "        [FN, TP]\n",
    "    ]\n",
    "\n",
    "    return confusion_matrix, TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MKRq0XYVBVWJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKRq0XYVBVWJ",
    "outputId": "322074e9-ebc3-46c1-d72f-49056cdf17df"
   },
   "outputs": [],
   "source": [
    "cm = compute_confusion_matrix(Y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TI7dBtH_A5QJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TI7dBtH_A5QJ",
    "outputId": "63ad34e8-9ea5-4e65-991f-1781257c4efe"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "TP, TN, FP, FN  = cm.ravel()\n",
    "\n",
    "\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mhMyvH2TB0MP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhMyvH2TB0MP",
    "outputId": "39a3965d-e93f-4a74-d2ba-102337c39954"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(TP, TN, FP, FN):\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "\n",
    "precision, recall, f1_score = calculate_metrics(TP, TN, FP, FN) # Calculate Precision, Recall, F1 Score\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yupquGNeCmxo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yupquGNeCmxo",
    "outputId": "8d3eb56f-112a-4de3-e7a3-ee874dada5fa"
   },
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(Y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"ROC-AUC Score: {auc_score:.4f}\") # Print the ROC-AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3QficeP2AooH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "3QficeP2AooH",
    "outputId": "fe209dc1-4324-4223-b1d8-1d39ef4bee9f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for regularization in regularizations:\n",
    "    accuracies = []\n",
    "    for lambda_param in lambda_params:\n",
    "        model = LogisticRegressionWithRegularization(learning_rate=0.01, num_iterations=1000, lambda_param=lambda_param, regularization=regularization)\n",
    "        model.fit(X_train_transformed, y_smote)\n",
    "        y_pred = model.predict(X_test_transformed)\n",
    "        accuracy = np.mean(y_pred == Y_test)\n",
    "        accuracies.append(accuracy)\n",
    "    ax.plot(lambda_params, accuracies, label=f'{regularization}')\n",
    "ax.set_xlabel('Lambda')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Comparison of Model Accuracy with Varying Lambda for Regularization Techniques')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eR2E9n5NmBS",
   "metadata": {
    "id": "6eR2E9n5NmBS"
   },
   "source": [
    "**Bias - Variance Trade-off**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gDw9K0509TBn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753
    },
    "id": "gDw9K0509TBn",
    "outputId": "612ff8cb-9820-40bc-8ffe-07f5fd4927b9"
   },
   "outputs": [],
   "source": [
    "X_train_1, X_temp, y_train_1, y_temp = train_test_split(x, y, stratify=y, test_size=0.4, random_state=42)\n",
    "X_cv_1, X_test_1, y_cv_1, y_test_1 = train_test_split(X_temp, y_temp, stratify=y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Applying SMOTE to handle imbalance in the training dataset\n",
    "smote = SMOTE(k_neighbors=20)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_1, y_train_1)\n",
    "\n",
    "# Print the class distributions after resampling\n",
    "print('Original dataset shape:', Counter(y_train_1))\n",
    "print('Resampled dataset shape:', Counter(y_train_smote))\n",
    "\n",
    "# Apply PCA to the oversampled data with 95% explained variance threshold\n",
    "pca = PCA(explained_variance_threshold=0.95)\n",
    "pca.fit(X_train_smote)\n",
    "\n",
    "X_train_transformed_1 = pca.transform(X_train_smote)\n",
    "X_cv_transformed_1 = pca.transform(X_cv_1)\n",
    "X_test_transformed_1 = pca.transform(X_test_1)\n",
    "\n",
    "lambdas = [0.1, 0.01, 0.001]  # Varying regularization strengths\n",
    "learning_rate = 0.1  # Use an optimal or constant learning rate\n",
    "regularization_type = 'ridge'  # Choose from 'ridge', 'lasso'\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "cv_errors = []\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "colors = ['r', 'g', 'b']\n",
    "labels = ['Lambda = 0.1', 'Lambda = 0.01', 'Lambda = 0.001']\n",
    "\n",
    "for lambda_param, color, label in zip(lambdas, colors, labels):\n",
    "    model = LogisticRegressionWithRegularization(learning_rate=learning_rate, lambda_param=lambda_param, regularization=regularization_type)\n",
    "    training_loss = model.fit(X_train_transformed_1, y_train_smote, return_history=True)\n",
    "    cv_loss = model.fit(X_cv_transformed_1, y_cv_1, return_history=True)\n",
    "    test_loss = model.fit(X_test_transformed_1, y_test_1, return_history=True)\n",
    "\n",
    "    y_pred_train = model.predict(X_train_transformed_1)\n",
    "    y_pred_val = model.predict(X_test_transformed_1)\n",
    "    cv_pred = model.predict(X_cv_transformed_1)\n",
    "\n",
    "    train_error = 1 - accuracy_score(y_train_smote, y_pred_train)\n",
    "    val_error = 1 - accuracy_score(y_test_1, y_pred_val)\n",
    "    cv_error = 1 - accuracy_score(y_cv_1, cv_pred)\n",
    "\n",
    "    # Plotting\n",
    "    plt.plot(range(1, model.num_iterations + 1), training_loss, color=color, linestyle='-', label=f'Training Loss {label}')\n",
    "    plt.plot(range(1, model.num_iterations + 1), cv_loss, color=color, linestyle='--', label=f'CV Loss {label}')\n",
    "    plt.plot(range(1, model.num_iterations + 1), test_loss, color=color, linestyle=':', label=f'Test Loss {label}')\n",
    "\n",
    "\n",
    "# Final plot adjustments\n",
    "plt.title('Training, CV, and Test Losses for Different Lambda Values - Bias Variance Tradeoff')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7VAQUsTS6iqv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "7VAQUsTS6iqv",
    "outputId": "49d13612-fdfd-4993-837b-dc8150ed4df8"
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Data setup\n",
    "data = {\n",
    "    'Learning Rate': [0.1]*9 + [0.01]*9 + [0.001]*9,\n",
    "    'Lambda': [0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001]*3,\n",
    "    'Regularization': ['ridge', 'lasso', 'None', 'ridge', 'lasso', 'None', 'ridge', 'lasso', 'None']*3,\n",
    "    'Accuracy': [\n",
    "        0.781, 0.63, 0.807, 0.804, 0.791, 0.807, 0.807, 0.806, 0.807,\n",
    "        0.766, 0.623, 0.782, 0.784, 0.757, 0.782, 0.782, 0.781, 0.782,\n",
    "        0.682, 0.635, 0.683, 0.682, 0.668, 0.683, 0.683, 0.681, 0.683\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "pivot_df = df.pivot_table(values='Accuracy', index='Lambda', columns=['Learning Rate', 'Regularization'], aggfunc='first')\n",
    "pivot_df = pivot_df.swaplevel(axis=1).sort_index(axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "fig.suptitle('Accuracy by Lambda and Learning Rate for Different Regularizations', fontsize=16)\n",
    "\n",
    "# Plot each regularization method in a different subplot\n",
    "for ax, reg in zip(axes, ['ridge', 'lasso', 'None']):\n",
    "    for lr in pivot_df.columns.levels[1]:\n",
    "        pivot_df[reg][lr].plot(ax=ax, marker='o', label=f'LR={lr}')\n",
    "    ax.set_title(f'Regularization: {reg}')\n",
    "    ax.set_xlabel('Lambda')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend(title='Learning Rate')\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ao28BTzcGssQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "ao28BTzcGssQ",
    "outputId": "8057ac7d-696f-4048-c361-dc48f29d2f62"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Data setup\n",
    "data = {\n",
    "    'Learning Rate': [0.1]*9 + [0.01]*9 + [0.001]*9,\n",
    "    'Lambda': [0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001]*3,\n",
    "    'Regularization': ['ridge', 'lasso', 'None', 'ridge', 'lasso', 'None', 'ridge', 'lasso', 'None']*3,\n",
    "    'Accuracy': [\n",
    "        0.781, 0.63, 0.807, 0.804, 0.791, 0.807, 0.807, 0.806, 0.807,\n",
    "        0.766, 0.623, 0.782, 0.784, 0.757, 0.782, 0.782, 0.781, 0.782,\n",
    "        0.682, 0.635, 0.683, 0.682, 0.668, 0.683, 0.683, 0.681, 0.683\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "pivot_df = df.pivot_table(values='Accuracy', index=['Lambda', 'Regularization'], columns='Learning Rate', aggfunc='mean')\n",
    "\n",
    "# Creating the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot_df, annot=True, cmap='viridis', fmt=\".3f\", linewidths=.5, cbar_kws={'label': 'Accuracy'})\n",
    "plt.title('Heatmap of Accuracy vs. Learning Rate, Lambda, and Regularization')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Lambda, Regularization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D7roaBBQFRBw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7roaBBQFRBw",
    "outputId": "46dce6b3-3fba-4a19-e52e-a511ed8893a3"
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters:\", best_params)\n",
    "best_model = LogisticRegressionWithRegularization(learning_rate=best_params['learning_rate'],\n",
    "                                                  lambda_param=best_params['lambda_param'],\n",
    "                                                  regularization=best_params['regularization'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B7CSYPO4KPVE",
   "metadata": {
    "id": "B7CSYPO4KPVE"
   },
   "source": [
    "Observations:The accuracy levels for the dataset that has been balanced using SMOTE and trained using logistic regression\n",
    "are generally higher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jc_NYTteKSb8",
   "metadata": {
    "id": "jc_NYTteKSb8"
   },
   "source": [
    "*Scenerio -2 *\n",
    "\n",
    "**LOGISTIC REGRESSION FOR UNDERSAMPLED DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vYpfs3xXKOLz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYpfs3xXKOLz",
    "outputId": "2d5a9bfc-22c9-44a7-847b-7aa3dc678d30"
   },
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CkjxYhigGIlH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "CkjxYhigGIlH",
    "outputId": "2f2449a6-53d6-4617-b466-62ea24c5e0ad"
   },
   "outputs": [],
   "source": [
    "df_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WsZv_uMXDwq-",
   "metadata": {
    "id": "WsZv_uMXDwq-"
   },
   "outputs": [],
   "source": [
    "x_for_undersampled= df_final.iloc[:, :-1]\n",
    "y_for_undersampled= df_final.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wNHpElAJGOyW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNHpElAJGOyW",
    "outputId": "afe3e39c-f26e-4f8d-a6b8-6e07d071881c"
   },
   "outputs": [],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X2UGCbS7Dy1N",
   "metadata": {
    "id": "X2UGCbS7Dy1N"
   },
   "outputs": [],
   "source": [
    "#split the dataset\n",
    "X_undersample_train, X_undersample_test, Y_undersample_train, Y_undersample_test = train_test_split(x_for_undersampled, y_for_undersampled, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x2-IdP7fD0-G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x2-IdP7fD0-G",
    "outputId": "d6c51e3c-14cf-47c8-9893-5afdd549cc04"
   },
   "outputs": [],
   "source": [
    "X_undersample_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EL_FFOgyD21J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EL_FFOgyD21J",
    "outputId": "de9bc500-7e88-42c8-e8ed-042b972a1eb6"
   },
   "outputs": [],
   "source": [
    "X_undersample_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3SVPkOjePSoj",
   "metadata": {
    "id": "3SVPkOjePSoj"
   },
   "source": [
    "**Under-Sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cxI_PUADD49s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxI_PUADD49s",
    "outputId": "60bd23c4-f874-4a98-9526-429a7c98291d"
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42, replacement=True)\n",
    "\n",
    "# fit predictor and target varialbe\n",
    "x_rus, y_rus = rus.fit_resample(X_undersample_train,Y_undersample_train)\n",
    "\n",
    "print('original dataset shape:', Counter(Y_undersample_train))\n",
    "print('Resample dataset shape', Counter(y_rus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cTJBvd8lPYYX",
   "metadata": {
    "id": "cTJBvd8lPYYX"
   },
   "source": [
    "PCA IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XDdSecVsD7yI",
   "metadata": {
    "id": "XDdSecVsD7yI"
   },
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, explained_variance_threshold=0.95):\n",
    "        self.explained_variance_threshold = explained_variance_threshold\n",
    "        self.n_components = None\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "\n",
    "        X -= self.mean\n",
    "\n",
    "        cov_matrix = np.cov(X.T) #  covariance matrix\n",
    "\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "        eigenvectors = eigenvectors.T\n",
    "        idxs = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvectors = eigenvectors[idxs]\n",
    "\n",
    "        explained_variance_ratio = np.cumsum(eigenvalues[idxs]) / np.sum(eigenvalues)\n",
    "        # Determine number of components to retain explained variance\n",
    "        self.n_components = np.argmax(explained_variance_ratio >= self.explained_variance_threshold) + 1\n",
    "        # Store the first n_components eigenvectors as principal components\n",
    "        self.components = eigenvectors[:self.n_components]\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        X -= self.mean\n",
    "        return np.dot(X, self.components.T) # Project data onto the principal components\n",
    "\n",
    "    def inverse_transform(self, X_transformed):\n",
    "\n",
    "        return np.dot(X_transformed, self.components) + self.mean # Transform data back to the original space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LOBOfL8jD96e",
   "metadata": {
    "id": "LOBOfL8jD96e"
   },
   "outputs": [],
   "source": [
    "# Apply PCA to the oversampled data with 95% explained variance threshold\n",
    "pca = PCA(explained_variance_threshold=0.95)\n",
    "pca.fit(x_rus)\n",
    "\n",
    "\n",
    "X_train_undersample_transformed = pca.transform(x_rus)\n",
    "X_test_undersample_transformed = pca.transform(X_undersample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bSv9UDlKEBVi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSv9UDlKEBVi",
    "outputId": "2b804265-7453-4133-801f-ae9975e19089"
   },
   "outputs": [],
   "source": [
    "X_train_undersample_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vbJbBrONEDUi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vbJbBrONEDUi",
    "outputId": "cdc087a2-9b39-440a-af62-3cefc4dfef4d"
   },
   "outputs": [],
   "source": [
    "X_test_undersample_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfUp9RfVGgkS",
   "metadata": {
    "id": "bfUp9RfVGgkS"
   },
   "outputs": [],
   "source": [
    "best_accuracy_rus = 0\n",
    "best_params_rus = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mSCDUZFKEIy7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSCDUZFKEIy7",
    "outputId": "6ff165f7-60d7-484a-ba92-a2badb8207c2"
   },
   "outputs": [],
   "source": [
    "for lr in learning_rates:\n",
    "    for lambda_param in lambda_params:\n",
    "        for regularization in regularizations:\n",
    "            model = LogisticRegressionWithRegularization(learning_rate=lr, lambda_param=lambda_param, regularization=regularization)\n",
    "            model.fit(X_train_undersample_transformed,y_rus)\n",
    "            y_pred_rus = model.predict(X_test_undersample_transformed)\n",
    "            accuracy_rus = np.mean(y_pred_rus == Y_undersample_test)\n",
    "            print(f\"Accuracy with lr={lr}, lambda={lambda_param}, regularization={regularization}  : {round(accuracy_rus,3)}\")\n",
    "            if accuracy_rus > best_accuracy_rus:\n",
    "                best_accuracy = accuracy_rus\n",
    "                best_params_rus = {'learning_rate': lr, 'lambda_param': lambda_param, 'regularization': regularization}\n",
    "\n",
    "print(\"Best parameters:\", best_params_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rnsaXfqgLYIQ",
   "metadata": {
    "id": "rnsaXfqgLYIQ"
   },
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Manually compute the confusion matrix for binary classification.\n",
    "\n",
    "    Args:\n",
    "    y_true (list or array): Actual true class labels.\n",
    "    y_pred (list or array): Predicted class labels.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (confusion_matrix, TP, TN, FP, FN)\n",
    "    \"\"\"\n",
    "    TP = TN = FP = FN = 0\n",
    "\n",
    "    for actual, predicted in zip(y_true, y_pred):\n",
    "        if actual == 1 and predicted == 1:\n",
    "            TP += 1\n",
    "        elif actual == 0 and predicted == 0:\n",
    "            TN += 1\n",
    "        elif actual == 0 and predicted == 1:\n",
    "            FP += 1\n",
    "        elif actual == 1 and predicted == 0:\n",
    "            FN += 1\n",
    "\n",
    "    confusion_matrix = [\n",
    "        [TN, FP],\n",
    "        [FN, TP]\n",
    "    ]\n",
    "\n",
    "    return confusion_matrix, TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zXIQ6m0xLcGs",
   "metadata": {
    "id": "zXIQ6m0xLcGs"
   },
   "outputs": [],
   "source": [
    "cm_rus = confusion_matrix(Y_undersample_test, y_pred_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yGJxB3i2NfN1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yGJxB3i2NfN1",
    "outputId": "25b72d7d-6c8c-4295-9c3f-c673bdce7454"
   },
   "outputs": [],
   "source": [
    "TN_rus, FP_rus, FN_rus, TP_rus = cm.ravel()\n",
    "\n",
    "# Display the confusion matrix and the individual components with formatted strings\n",
    "print(f\"True Positives (TP): {TP_rus}\")\n",
    "print(f\"True Negatives (TN): {TN_rus}\")\n",
    "print(f\"False Positives (FP): {FP_rus}\")\n",
    "print(f\"False Negatives (FN): {FN_rus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n3Nr38oENxJr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3Nr38oENxJr",
    "outputId": "7ce9b2f3-99d5-4b54-c094-e5e4f1673dd1"
   },
   "outputs": [],
   "source": [
    "# Calculate Precision, Recall, F1 Score\n",
    "precision_rus = TP_rus / (TP_rus + FP_rus)\n",
    "recall_rus = TP_rus / (TP_rus + FN_rus)\n",
    "\n",
    "f1_score_rus = 2 * (precision_rus * recall_rus) / (precision_rus + recall_rus)\n",
    "print(f\"Precision: {precision_rus:.4f}\")\n",
    "print(f\"Recall: {recall_rus:.4f}\")\n",
    "print(f\"F1 Score: {f1_score_rus:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007NRLbrbJkh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "007NRLbrbJkh",
    "outputId": "6383cfc3-30a2-4cda-d000-e42abf1883e0"
   },
   "outputs": [],
   "source": [
    "auc_score_rus = roc_auc_score(Y_undersample_test, y_pred_rus)\n",
    "\n",
    "\n",
    "print(f\"ROC-AUC Score: {auc_score_rus:.4f}\") # Print the ROC-AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "__T9dqhkOEot",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "__T9dqhkOEot",
    "outputId": "59e500cf-7af9-4289-b242-cb04fbba2964"
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Data setup\n",
    "data_rus = {\n",
    "    'Learning Rate': [0.1]*9 + [0.01]*9 + [0.001]*9,\n",
    "    'Lambda': [0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001]*3,\n",
    "    'Regularization': ['ridge', 'lasso', 'None', 'ridge', 'lasso', 'None', 'ridge', 'lasso', 'None']*3,\n",
    "    'Accuracy': [\n",
    "        0.651, 0.62, 0.699, 0.687, 0.604, 0.699, 0.698, 0.696, 0.699,\n",
    "        0.657, 0.617, 0.688, 0.681, 0.682, 0.688, 0.687, 0.684, 0.688,\n",
    "        0.668, 0.631, 0.671, 0.671, 0.661, 0.671, 0.671, 0.67, 0.671\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "df_rus = pd.DataFrame(data_rus)\n",
    "\n",
    "pivot_df_rus = df_rus.pivot_table(values='Accuracy', index='Lambda', columns=['Learning Rate', 'Regularization'], aggfunc='first')\n",
    "pivot_df_rus = pivot_df_rus.swaplevel(axis=1).sort_index(axis=1)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "fig.suptitle('Accuracy by Lambda and Learning Rate for Different Regularizations', fontsize=16)\n",
    "\n",
    "# Plot each regularization method in a different subplot\n",
    "for ax, reg in zip(axes, ['ridge', 'lasso', 'None']):\n",
    "    for lr in pivot_df_rus.columns.levels[1]:\n",
    "        pivot_df_rus[reg][lr].plot(ax=ax, marker='o', label=f'LR={lr}')\n",
    "    ax.set_title(f'Regularization: {reg}')\n",
    "    ax.set_xlabel('Lambda')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend(title='Learning Rate')\n",
    "\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QQKlmu90c4dE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "QQKlmu90c4dE",
    "outputId": "b17f82a6-572a-43f0-bcf8-6d554aaaade3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Data setup\n",
    "data_rus = {\n",
    "    'Learning Rate': [0.1]*9 + [0.01]*9 + [0.001]*9,\n",
    "    'Lambda': [0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001]*3,\n",
    "    'Regularization': ['ridge', 'lasso', 'None', 'ridge', 'lasso', 'None', 'ridge', 'lasso', 'None']*3,\n",
    "    'Accuracy': [\n",
    "        0.651, 0.62, 0.699, 0.687, 0.604, 0.699, 0.698, 0.696, 0.699,\n",
    "        0.657, 0.617, 0.688, 0.681, 0.682, 0.688, 0.687, 0.684, 0.688,\n",
    "        0.668, 0.631, 0.671, 0.671, 0.661, 0.671, 0.671, 0.67, 0.671\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "df_rus = pd.DataFrame(data_rus)\n",
    "\n",
    "\n",
    "pivot_df_rus = df_rus.pivot_table(values='Accuracy', index=['Lambda', 'Regularization'], columns='Learning Rate', aggfunc='mean')\n",
    "\n",
    "# Creating the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pivot_df_rus, annot=True, cmap='viridis', fmt=\".3f\", linewidths=.5, cbar_kws={'label': 'Accuracy'})\n",
    "plt.title('Heatmap of Accuracy vs. Learning Rate, Lambda, and Regularization')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Lambda, Regularization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bnL9bYRgIV6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "bnL9bYRgIV6a",
    "outputId": "d0cd23cc-e7ac-456d-f679-a406f6af6af2"
   },
   "outputs": [],
   "source": [
    "X_undersample_train_rus, X_undersample_temp, Y_undersample_train_rus, Y_undersample_temp = train_test_split(x_for_undersampled, y_for_undersampled, test_size=0.4)\n",
    "X_undersample_cv_rus, X_undersample_test_rus, y_undersample_cv_rus, y_undersample_test_rus = train_test_split(X_undersample_temp, Y_undersample_temp, stratify=Y_undersample_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Apply PCA to the oversampled data with 95% explained variance threshold\n",
    "pca = PCA(explained_variance_threshold=0.95)\n",
    "pca.fit(X_undersample_train)\n",
    "\n",
    "# Transform the oversampled data onto the new lower-dimensional space\n",
    "X_train_undersample_transformed_1 = pca.transform(X_undersample_train_rus)\n",
    "X_cv_undersample_transformed_1 = pca.transform(X_undersample_cv_rus)\n",
    "X_test_undersample_transformed_1 = pca.transform(X_undersample_test_rus)\n",
    "\n",
    "\n",
    "\n",
    "lambdas = [0.1, 0.01, 0.001]  # Varying regularization strengths\n",
    "learning_rate = 0.1  # Use an optimal or constant learning rate\n",
    "regularization_type = 'ridge'  # Choose from 'ridge', 'lasso'\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "cv_errors = []\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "colors = ['r', 'g', 'b']\n",
    "labels = ['Lambda = 0.1', 'Lambda = 0.01', 'Lambda = 0.001']\n",
    "\n",
    "for lambda_param, color, label in zip(lambdas, colors, labels):\n",
    "    model_rus = LogisticRegressionWithRegularization(learning_rate=learning_rate, lambda_param=lambda_param, regularization=regularization_type)\n",
    "    training_loss_rus = model_rus.fit(X_train_undersample_transformed_1, Y_undersample_train_rus, return_history=True)\n",
    "    cv_loss_rus = model_rus.fit(X_cv_undersample_transformed_1, y_undersample_cv_rus, return_history=True)\n",
    "    test_loss_rus = model_rus.fit(X_test_undersample_transformed_1, y_undersample_test_rus, return_history=True)\n",
    "\n",
    "    y_pred_train_rus = model.predict(X_train_undersample_transformed_1)\n",
    "    y_pred_val_rus = model.predict(X_test_undersample_transformed_1)\n",
    "    cv_pred_rus = model.predict(X_cv_undersample_transformed_1)\n",
    "\n",
    "    train_error_rus = 1 - accuracy_score(Y_undersample_train_rus, y_pred_train_rus)\n",
    "    val_error_rus = 1 - accuracy_score(y_undersample_test_rus, y_pred_val_rus)\n",
    "    cv_error_rus = 1 - accuracy_score(y_undersample_cv_rus, cv_pred_rus)\n",
    "\n",
    "    # Plotting\n",
    "    plt.plot(range(1, model.num_iterations + 1), training_loss_rus, color=color, linestyle='-', label=f'Training Loss {label}')\n",
    "    plt.plot(range(1, model.num_iterations + 1), cv_loss_rus, color=color, linestyle='--', label=f'CV Loss {label}')\n",
    "    plt.plot(range(1, model.num_iterations + 1), test_loss_rus, color=color, linestyle=':', label=f'Test Loss {label}')\n",
    "\n",
    "\n",
    "# Final plot adjustments\n",
    "plt.title('Training, CV, and Test Losses for Different Lambda Values - Bias Variance Tradeoff')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
